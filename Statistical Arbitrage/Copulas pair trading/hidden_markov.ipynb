{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Jays-code-collection/HMMs_Stock_Market\n",
    "\n",
    "first im going to decompose his code into a notebook, and then combine it and explain it in my own way\n",
    "\n",
    "the hidden markov model is used to score the likelihood of an event occuring given the previous 10 days\n",
    "\n",
    "can i use the one day predictions to do one day expiring options?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas_datareader import data\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from datetime import timedelta\n",
    "#gjhgjhgjhgjhgjhgjhg\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"AAPL\"\n",
    "start_date = \"2018-01-01\"\n",
    "end_date = \"2020-12-05\"\n",
    "n_latency_days = 10\n",
    "hmm = GaussianHMM(n_components=4) # 4 is number of hidden states\n",
    "predicted_close = None # not sure what for\n",
    "days_in_future = 5\n",
    "\n",
    "n_intervals_frac_change=50\n",
    "n_intervals_frac_high=10\n",
    "n_intervals_frac_low=10\n",
    "test_size=0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# download the data (split train test)\n",
    "\n",
    "import yfinance as yfin\n",
    "yfin.pdr_override()\n",
    "\n",
    "used_data = data.get_data_yahoo(company, start_date, end_date)\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "            used_data, test_size=test_size, shuffle=False\n",
    "        )\n",
    "\n",
    "train_data = train_data.drop([\"Volume\", \"Adj Close\"], axis=1)\n",
    "test_data = test_data.drop([\"Volume\", \"Adj Close\"], axis=1)\n",
    "\n",
    "days = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the test features of the data\n",
    "def _extract_features(data):\n",
    "    \"\"\"Extract the features - open, close, high, low price - from the Yahooo finance generated dataframe.\"\"\"\n",
    "    open_price = np.array(data[\"Open\"])\n",
    "    close_price = np.array(data[\"Close\"])\n",
    "    high_price = np.array(data[\"High\"])\n",
    "    low_price = np.array(data[\"Low\"])\n",
    "\n",
    "    # We compute the fractional change in high,low and close prices to use as our set of observations\n",
    "    frac_change = (close_price - open_price) / open_price\n",
    "    frac_high = (high_price - open_price) / open_price\n",
    "    frac_low = (open_price - low_price) / open_price\n",
    "\n",
    "    # Put the observations into one array\n",
    "    return np.column_stack((frac_change, frac_high, frac_low))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the hidden markov model to the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianHMM(n_components=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianHMM</label><div class=\"sk-toggleable__content\"><pre>GaussianHMM(n_components=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianHMM(n_components=4)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = _extract_features(train_data)\n",
    "hmm.fit(observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute all possible outcomes\n",
    "\n",
    "Creates np arrays with evenly  spaced numbers for each range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_change_range = np.linspace(-0.1, 0.1, n_intervals_frac_change)\n",
    "frac_high_range = np.linspace(0, 0.1, n_intervals_frac_high)\n",
    "frac_low_range = np.linspace(0, 0.1, n_intervals_frac_low)\n",
    "\n",
    "_possible_outcomes = np.array(\n",
    "    list(itertools.product(frac_change_range, frac_high_range, frac_low_range))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the fitted HMM, calculate the most probable outcome for a given day (e.g. prices will rise by 0.01).\n",
    "        :param day_index: Current day index\n",
    "        :return: The HMM's predicted movements in frac_change, frac_high, frac_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00204082,  0.01111111,  0.01111111])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_index = 2\n",
    "\n",
    "# Use the previous n_latency_days worth of data for predictions\n",
    "previous_data_start_index = max(0, day_index - n_latency_days)\n",
    "previous_data_end_index = max(0, day_index - 1)\n",
    "previous_data = test_data.iloc[\n",
    "    previous_data_start_index:previous_data_end_index\n",
    "]\n",
    "previous_data_features = _extract_features(previous_data)\n",
    "\n",
    "outcome_score = []\n",
    "\n",
    "# Score all possible outcomes and select the most probable one to use for prediction\n",
    "for possible_outcome in _possible_outcomes:\n",
    "    total_data = np.row_stack((previous_data_features, possible_outcome))\n",
    "    outcome_score.append(hmm.score(total_data))\n",
    "\n",
    "# Get the index of the most probable outcome and return it\n",
    "most_probable_outcome = _possible_outcomes[np.argmax(outcome_score)]\n",
    "\n",
    "most_probable_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict close price for a given day. (using most probable outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.11297867444097"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_price = test_data.iloc[day_index][\"Open\"]\n",
    "(\n",
    "    predicted_frac_change,\n",
    "    pred_frac_high,\n",
    "    pred_frac_low,\n",
    ") = most_probable_outcome\n",
    "predicted_close_price = open_price * (1 + predicted_frac_change)\n",
    "\n",
    "predicted_close_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict close prices for the testing period.\n",
    "\n",
    "\n",
    ":return: List object of predicted close prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMMStockPredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        company,\n",
    "        start_date,\n",
    "        end_date,\n",
    "        future_days,\n",
    "        test_size=0.33,\n",
    "        n_hidden_states=4,\n",
    "        n_latency_days=10,\n",
    "        n_intervals_frac_change=50,\n",
    "        n_intervals_frac_high=10,\n",
    "        n_intervals_frac_low=10,\n",
    "    ):\n",
    "        self._init_logger()\n",
    "        self.company = company\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.n_latency_days = n_latency_days\n",
    "        self.hmm = GaussianHMM(n_components=n_hidden_states)\n",
    "        self._split_train_test_data(test_size)\n",
    "        self._compute_all_possible_outcomes(\n",
    "            n_intervals_frac_change, n_intervals_frac_high, n_intervals_frac_low\n",
    "        )\n",
    "        self.predicted_close = None\n",
    "        self.days_in_future = future_days\n",
    "\n",
    "    def _init_logger(self):\n",
    "        self._logger = logging.getLogger(__name__)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter(\n",
    "            \"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\"\n",
    "        )\n",
    "        handler.setFormatter(formatter)\n",
    "        self._logger.addHandler(handler)\n",
    "        self._logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    def _split_train_test_data(self, test_size):\n",
    "        \"\"\"Downloads data and splits it into training and testing datasets.\"\"\"\n",
    "        # Use pandas_reader.data.DataReader to load the required financial data. Checks if the stock entry is valid.\n",
    "\n",
    "        #* fixing error\n",
    "        import yfinance as yfin\n",
    "        yfin.pdr_override()\n",
    "\n",
    "        try:\n",
    "            # used_data = data.DataReader(\n",
    "            #     self.company, \"yahoo\", self.start_date, self.end_date\n",
    "            # )\n",
    "            used_data = data.get_data_yahoo(self.company, self.start_date, self.end_date)\n",
    "        except IOError:\n",
    "            print(\n",
    "                \"Invalid stock selection. Please try again with a stock that is available on Yahoo finance.\"\n",
    "            )\n",
    "            sys.exit()\n",
    "        # Do not shuffle the data as it is a time series\n",
    "        _train_data, test_data = train_test_split(\n",
    "            used_data, test_size=test_size, shuffle=False\n",
    "        )\n",
    "        self.train_data = _train_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "        # Drop the columns that aren't used\n",
    "        self.train_data = self.train_data.drop([\"Volume\", \"Adj Close\"], axis=1)\n",
    "        self.test_data = self.test_data.drop([\"Volume\", \"Adj Close\"], axis=1)\n",
    "\n",
    "        # Set days attribute\n",
    "        self.days = len(test_data)\n",
    "\n",
    "    @staticmethod\n",
    "    def _extract_features(data):\n",
    "        \"\"\"Extract the features - open, close, high, low price - from the Yahooo finance generated dataframe.\"\"\"\n",
    "        open_price = np.array(data[\"Open\"])\n",
    "        close_price = np.array(data[\"Close\"])\n",
    "        high_price = np.array(data[\"High\"])\n",
    "        low_price = np.array(data[\"Low\"])\n",
    "\n",
    "        # We compute the fractional change in high,low and close prices to use as our set of observations\n",
    "        frac_change = (close_price - open_price) / open_price\n",
    "        frac_high = (high_price - open_price) / open_price\n",
    "        frac_low = (open_price - low_price) / open_price\n",
    "\n",
    "        # Put the observations into one array\n",
    "        return np.column_stack((frac_change, frac_high, frac_low))\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the continuous emission Gaussian HMM.\"\"\"\n",
    "        self._logger.info(\">>> Extracting Features\")\n",
    "        observations = HMMStockPredictor._extract_features(self.train_data)\n",
    "        self._logger.info(\"Features extraction Completed <<<\")\n",
    "        # Fit the HMM using the fit feature of hmmlearn\n",
    "        self.hmm.fit(observations)\n",
    "\n",
    "    def _compute_all_possible_outcomes(\n",
    "        self, n_intervals_frac_change, n_intervals_frac_high, n_intervals_frac_low\n",
    "    ):\n",
    "        \"\"\"Creates np arrays with evenly  spaced numbers for each range.\"\"\"\n",
    "        frac_change_range = np.linspace(-0.1, 0.1, n_intervals_frac_change)\n",
    "        frac_high_range = np.linspace(0, 0.1, n_intervals_frac_high)\n",
    "        frac_low_range = np.linspace(0, 0.1, n_intervals_frac_low)\n",
    "\n",
    "        self._possible_outcomes = np.array(\n",
    "            list(itertools.product(frac_change_range, frac_high_range, frac_low_range))\n",
    "        )\n",
    "\n",
    "    def _get_most_probable_outcome(self, day_index):\n",
    "        \"\"\"\n",
    "        Using the fitted HMM, calculate the most probable outcome for a given day (e.g. prices will rise by 0.01).\n",
    "        :param day_index: Current day index\n",
    "        :return: The HMM's predicted movements in frac_change, frac_high, frac_low\n",
    "        \"\"\"\n",
    "        # Use the previous n_latency_days worth of data for predictions\n",
    "        previous_data_start_index = max(0, day_index - self.n_latency_days)\n",
    "        previous_data_end_index = max(0, day_index - 1)\n",
    "        previous_data = self.test_data.iloc[\n",
    "            previous_data_start_index:previous_data_end_index\n",
    "        ]\n",
    "        previous_data_features = HMMStockPredictor._extract_features(previous_data)\n",
    "\n",
    "        outcome_score = []\n",
    "\n",
    "        # Score all possible outcomes and select the most probable one to use for prediction\n",
    "        for possible_outcome in self._possible_outcomes:\n",
    "            total_data = np.row_stack((previous_data_features, possible_outcome))\n",
    "            outcome_score.append(self.hmm.score(total_data)) # get the log likelihood of that outcome occuring\n",
    "\n",
    "        # Get the index of the most probable outcome and return it\n",
    "        most_probable_outcome = self._possible_outcomes[np.argmax(outcome_score)]\n",
    "\n",
    "        return most_probable_outcome\n",
    "\n",
    "    def predict_close_price(self, day_index):\n",
    "        \"\"\"Predict close price for a given day.\"\"\"\n",
    "        open_price = self.test_data.iloc[day_index][\"Open\"]\n",
    "        (\n",
    "            predicted_frac_change,\n",
    "            pred_frac_high,\n",
    "            pred_frac_low,\n",
    "        ) = self._get_most_probable_outcome(day_index)\n",
    "        return open_price * (1 + predicted_frac_change)\n",
    "\n",
    "    def predict_close_prices_for_period(self):\n",
    "        \"\"\"\n",
    "        Predict close prices for the testing period.\n",
    "        :return: List object of predicted close prices\n",
    "        \"\"\"\n",
    "        predicted_close_prices = []\n",
    "        print(\n",
    "            \"Predicting Close prices from \"\n",
    "            + str(self.test_data.index[0])\n",
    "            + \" to \"\n",
    "            + str(self.test_data.index[-1])\n",
    "        )\n",
    "        for day_index in tqdm(range(self.days)):\n",
    "            predicted_close_prices.append(self.predict_close_price(day_index))\n",
    "        self.predicted_close = predicted_close_prices\n",
    "        return predicted_close_prices\n",
    "\n",
    "    def real_close_prices(self):\n",
    "        \"\"\" \"Store and return the actual close prices.\"\"\"\n",
    "        actual_close_prices = self.test_data.loc[:, [\"Close\"]]\n",
    "        return actual_close_prices\n",
    "\n",
    "    def add_future_days(self):\n",
    "        \"\"\"\n",
    "        Add rows to the test data dataframe for the future days being predicted with accurate days. The rows are left\n",
    "        with NaN values for now as they will be populated whilst predicting.\n",
    "        \"\"\"\n",
    "        last_day = self.test_data.index[-1] + timedelta(days=self.days_in_future)\n",
    "\n",
    "        # Create a new df with future days x days in the future based off the -f input. Concat the new df with\n",
    "        # self.test_data.\n",
    "        future_dates = pd.date_range(\n",
    "            self.test_data.index[-1] + pd.offsets.DateOffset(1), last_day\n",
    "        )\n",
    "        second_df = pd.DataFrame(\n",
    "            index=future_dates, columns=[\"Open\", \"High\", \"Low\", \"Close\"]\n",
    "        )\n",
    "        self.test_data = pd.concat([self.test_data, second_df])\n",
    "\n",
    "        # Replace the opening price for the first day in the future with the close price of the previous day\n",
    "        self.test_data.iloc[self.days][\"Open\"] = self.test_data.iloc[self.days - 1][\n",
    "            \"Close\"\n",
    "        ]\n",
    "\n",
    "    def predict_close_price_fut_days(self, day_index):\n",
    "        \"\"\"\n",
    "        Predict the close prices for the days in the future beyond the available data and populate the DF accordingly.\n",
    "        :param day_index - index in DF for  current day being predicted.\n",
    "        :return: Predicted close price for given day.\n",
    "        \"\"\"\n",
    "        open_price = self.test_data.iloc[day_index][\"Open\"]\n",
    "\n",
    "        # Calculate the most likely fractional changes using the trained HMM\n",
    "        (\n",
    "            predicted_frac_change,\n",
    "            pred_frac_high,\n",
    "            pred_frac_low,\n",
    "        ) = self._get_most_probable_outcome(day_index)\n",
    "        predicted_close_price = open_price * (1 + predicted_frac_change)\n",
    "\n",
    "        # Fill in the dataframe based on predictions\n",
    "        self.test_data.iloc[day_index][\"Close\"] = predicted_close_price\n",
    "        self.test_data.iloc[day_index][\"High\"] = open_price * (1 + pred_frac_high)\n",
    "        self.test_data.iloc[day_index][\"Low\"] = open_price * (1 - pred_frac_low)\n",
    "        print(predicted_close_price)\n",
    "\n",
    "        return predicted_close_price\n",
    "\n",
    "    def predict_close_prices_for_future(self):\n",
    "        \"\"\"\n",
    "        Calls the \"predict_close_price_fut_days\" function for each day in the future to predict future close prices.\n",
    "        \"\"\"\n",
    "        predicted_close_prices = []\n",
    "        future_indices = len(self.test_data) - self.days_in_future\n",
    "        print(\n",
    "            \"Predicting future Close prices from \"\n",
    "            + str(self.test_data.index[future_indices])\n",
    "            + \" to \"\n",
    "            + str(self.test_data.index[-1])\n",
    "        )\n",
    "        self.test_data.iloc[future_indices][\"Open\"] = self.test_data.iloc[\n",
    "                    future_indices - 1\n",
    "                ][\"Close\"]\n",
    "        # Iterate over only the final x days in the test data dataframe.\n",
    "        for _day_index in tqdm(range(future_indices, len(self.test_data))):\n",
    "            predicted_close_prices.append(self.predict_close_price_fut_days(_day_index))\n",
    "            # Replace the next days Opening price (which is currently NaN) with the previous days predicted close price\n",
    "            try:\n",
    "                self.test_data.iloc[_day_index + 1][\"Open\"] = self.test_data.iloc[\n",
    "                    _day_index\n",
    "                ][\"Close\"]\n",
    "            except IndexError:\n",
    "                continue\n",
    "\n",
    "        # Return the predicted close prices\n",
    "        self.predicted_close = predicted_close_prices\n",
    "\n",
    "        return predicted_close_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,372 __main__     INFO     >>> Extracting Features\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n",
      "2023-09-23 19:37:37,387 __main__     INFO     Features extraction Completed <<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "company = 'AAPL'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2023-01-01'\n",
    "days_in_future = None\n",
    "stock_predictor = HMMStockPredictor(company=company, start_date=start_date, end_date=end_date, future_days=days_in_future)\n",
    "stock_predictor.fit()\n",
    "# future\n",
    "# stock_predictor.add_future_days()\n",
    "\n",
    "# future_pred_close = stock_predictor.predict_close_prices_for_future()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a strategy where if the open price of the day is predicted to go up past some threshold, buy the stock by some weight, if it is thought to go down past a threshold then sell by some weight. Exit all trades at the end of each day\n",
    "\n",
    "maybe retrain the model on the past months data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = \"^GSPC\"\n",
    "start_date = \"2020-01-01\"\n",
    "end_date = \"2023-01-01\"\n",
    "n_latency_days = 10\n",
    "hmm = GaussianHMM(n_components=4) # 4 is number of hidden states\n",
    "predicted_close = None # not sure what for\n",
    "days_in_future = 5\n",
    "\n",
    "n_intervals_frac_change=50\n",
    "n_intervals_frac_high=10\n",
    "n_intervals_frac_low=10\n",
    "test_size=0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# download the data (split train test)\n",
    "\n",
    "import yfinance as yfin\n",
    "yfin.pdr_override()\n",
    "\n",
    "used_data = data.get_data_yahoo(company, start_date, end_date)\n",
    "\n",
    "train_data, test_data = train_test_split(\n",
    "            used_data, test_size=test_size, shuffle=False\n",
    "        )\n",
    "\n",
    "train_data = train_data.drop([\"Volume\", \"Adj Close\"], axis=1)\n",
    "test_data = test_data.drop([\"Volume\", \"Adj Close\"], axis=1)\n",
    "\n",
    "days = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the test features of the data\n",
    "def _extract_features(data):\n",
    "    \"\"\"Extract the features - open, close, high, low price - from the Yahooo finance generated dataframe.\"\"\"\n",
    "    open_price = np.array(data[\"Open\"])\n",
    "    close_price = np.array(data[\"Close\"])\n",
    "    high_price = np.array(data[\"High\"])\n",
    "    low_price = np.array(data[\"Low\"])\n",
    "\n",
    "    # We compute the fractional change in high,low and close prices to use as our set of observations\n",
    "    frac_change = (close_price - open_price) / open_price\n",
    "    frac_high = (high_price - open_price) / open_price\n",
    "    frac_low = (open_price - low_price) / open_price\n",
    "\n",
    "    # Put the observations into one array\n",
    "    return np.column_stack((frac_change, frac_high, frac_low))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model is not converging.  Current: 5287.529451104843 is not greater than 5289.702126282505. Delta is -2.1726751776614037\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianHMM(n_components=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianHMM</label><div class=\"sk-toggleable__content\"><pre>GaussianHMM(n_components=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianHMM(n_components=4)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = _extract_features(train_data)\n",
    "hmm.fit(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1       ,  0.        ,  0.        ],\n",
       "       [-0.1       ,  0.        ,  0.01111111],\n",
       "       [-0.1       ,  0.        ,  0.02222222],\n",
       "       ...,\n",
       "       [ 0.1       ,  0.1       ,  0.07777778],\n",
       "       [ 0.1       ,  0.1       ,  0.08888889],\n",
       "       [ 0.1       ,  0.1       ,  0.1       ]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac_change_range = np.linspace(-0.1, 0.1, n_intervals_frac_change)\n",
    "frac_high_range = np.linspace(0, 0.1, n_intervals_frac_high)\n",
    "frac_low_range = np.linspace(0, 0.1, n_intervals_frac_low)\n",
    "\n",
    "_possible_outcomes = np.array(\n",
    "    list(itertools.product(frac_change_range, frac_high_range, frac_low_range))\n",
    ")\n",
    "_possible_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00204082,  0.        ,  0.01111111])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_most_probable_outcome(_day_index):\n",
    "    # Use the previous n_latency_days worth of data for predictions\n",
    "    previous_data_start_index = max(0, _day_index - n_latency_days)\n",
    "    previous_data_end_index = max(0, _day_index - 1)\n",
    "    previous_data = test_data.iloc[\n",
    "        previous_data_start_index:previous_data_end_index\n",
    "    ]\n",
    "    previous_data_features = _extract_features(previous_data)\n",
    "\n",
    "    outcome_score = []\n",
    "    # Score all possible outcomes and select the most probable one to use for prediction\n",
    "    for possible_outcome in _possible_outcomes:\n",
    "        total_data = np.row_stack((previous_data_features, possible_outcome))\n",
    "        outcome_score.append(hmm.score(total_data))\n",
    "\n",
    "    # Get the index of the most probable outcome and return it\n",
    "    most_probable_outcome = _possible_outcomes[np.argmax(outcome_score)]\n",
    "\n",
    "    return most_probable_outcome\n",
    "get_most_probable_outcome(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_close_price(_day_index):\n",
    "        \"\"\"Predict close price for a given day.\"\"\"\n",
    "        open_price = test_data.iloc[_day_index][\"Open\"]\n",
    "        (\n",
    "            predicted_frac_change,\n",
    "            pred_frac_high,\n",
    "            pred_frac_low,\n",
    "        ) = get_most_probable_outcome(_day_index)\n",
    "        return open_price * (1 + predicted_frac_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4069.108646065848, 4158.240234375)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_index = 100\n",
    "get_predicted_close_price(day_index), test_data.iloc[day_index][\"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-22.98974609375, -9.31916354432451)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_index = 20\n",
    "(test_data.iloc[day_index][\"Open\"] - test_data.iloc[day_index][\"Close\"]), (test_data.iloc[day_index][\"Open\"] - get_predicted_close_price(day_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_index=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:19<00:00,  3.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def backtest_strategy(\n",
    "        company = \"^GSPC\",\n",
    "        start_date = \"2020-01-01\",\n",
    "        end_date = \"2023-01-01\",\n",
    "        n_latency_days = 10,\n",
    "        n_hidden_states = 4,\n",
    "        days_in_future = 5,\n",
    "\n",
    "        n_intervals_frac_change=50,\n",
    "        n_intervals_frac_high=10,\n",
    "        n_intervals_frac_low=10,\n",
    "        test_size=0.33\n",
    "):\n",
    "        correct = 0\n",
    "        hmm = GaussianHMM(n_components=n_hidden_states)\n",
    "        ### Download data\n",
    "        import yfinance as yfin\n",
    "        yfin.pdr_override()\n",
    "\n",
    "        used_data = data.get_data_yahoo(company, start_date, end_date)\n",
    "\n",
    "        train_data, test_data = train_test_split(\n",
    "                used_data, test_size=test_size, shuffle=False\n",
    "                )\n",
    "\n",
    "        train_data = train_data.drop([\"Volume\", \"Adj Close\"], axis=1)\n",
    "        test_data = test_data.drop([\"Volume\", \"Adj Close\"], axis=1)\n",
    "\n",
    "        frac_change_range = np.linspace(-0.1, 0.1, n_intervals_frac_change)\n",
    "        frac_high_range = np.linspace(0, 0.1, n_intervals_frac_high)\n",
    "        frac_low_range = np.linspace(0, 0.1, n_intervals_frac_low)\n",
    "\n",
    "        _possible_outcomes = np.array(\n",
    "        list(itertools.product(frac_change_range, frac_high_range, frac_low_range))\n",
    "        )\n",
    "\n",
    "        def _extract_features(data):\n",
    "                \"\"\"Extract the features - open, close, high, low price - from the Yahooo finance generated dataframe.\"\"\"\n",
    "                open_price = np.array(data[\"Open\"])\n",
    "                close_price = np.array(data[\"Close\"])\n",
    "                high_price = np.array(data[\"High\"])\n",
    "                low_price = np.array(data[\"Low\"])\n",
    "\n",
    "                # We compute the fractional change in high,low and close prices to use as our set of observations\n",
    "                frac_change = (close_price - open_price) / open_price\n",
    "                frac_high = (high_price - open_price) / open_price\n",
    "                frac_low = (open_price - low_price) / open_price\n",
    "\n",
    "                # Put the observations into one array\n",
    "                return np.column_stack((frac_change, frac_high, frac_low))\n",
    "        \n",
    "        observations = _extract_features(train_data)\n",
    "        hmm.fit(observations)\n",
    "        \n",
    "        def get_most_probable_outcome(_day_index):\n",
    "                # Use the previous n_latency_days worth of data for predictions\n",
    "                previous_data_start_index = max(0, _day_index - n_latency_days)\n",
    "                previous_data_end_index = max(0, _day_index - 1)\n",
    "                previous_data = test_data.iloc[\n",
    "                        previous_data_start_index:previous_data_end_index\n",
    "                ]\n",
    "                previous_data_features = _extract_features(previous_data)\n",
    "\n",
    "                outcome_score = []\n",
    "                # Score all possible outcomes and select the most probable one to use for prediction\n",
    "                for possible_outcome in _possible_outcomes:\n",
    "                        total_data = np.row_stack((previous_data_features, possible_outcome))\n",
    "                        outcome_score.append(hmm.score(total_data))\n",
    "\n",
    "                # Get the index of the most probable outcome and return it\n",
    "                most_probable_outcome = _possible_outcomes[np.argmax(outcome_score)]\n",
    "\n",
    "                return most_probable_outcome\n",
    "        \n",
    "        def get_predicted_close_price(_day_index):\n",
    "                \"\"\"Predict close price for a given day.\"\"\"\n",
    "                open_price = test_data.iloc[_day_index][\"Open\"]\n",
    "                (\n",
    "                predicted_frac_change,\n",
    "                pred_frac_high,\n",
    "                pred_frac_low,\n",
    "                ) = get_most_probable_outcome(_day_index)\n",
    "                return open_price * (1 + predicted_frac_change)\n",
    "        \n",
    "        for day_index in tqdm(range(len(test_data))):\n",
    "                current_open_price = test_data.iloc[day_index][\"Open\"]\n",
    "                current_close_price = test_data.iloc[day_index][\"Close\"]\n",
    "                x = current_open_price - current_close_price\n",
    "                y = current_open_price - get_predicted_close_price(day_index)\n",
    "                if x*y > 0:\n",
    "                        correct += 1\n",
    "        # correct days/all days\n",
    "        print(correct/len(test_data)) \n",
    "\n",
    "backtest_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "investigate a new model for predicting if the stock will go up or not, rather than the amoutn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2175187026.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m\u001b[0m\n\u001b[0;31m    from openbb import openbb.sdk as obb\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import openbb as obb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openbb' has no attribute 'stocks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jasperchong/PycharmProjects/Statistical Arbitrage/Copulas pair trading/hidden_markov.ipynb Cell 32\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasperchong/PycharmProjects/Statistical%20Arbitrage/Copulas%20pair%20trading/hidden_markov.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Get the nominal price returns for 2022\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jasperchong/PycharmProjects/Statistical%20Arbitrage/Copulas%20pair%20trading/hidden_markov.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m stocks_dataframe \u001b[39m=\u001b[39m obb\u001b[39m.\u001b[39;49mstocks\u001b[39m.\u001b[39mload(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasperchong/PycharmProjects/Statistical%20Arbitrage/Copulas%20pair%20trading/hidden_markov.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mBMWYY\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasperchong/PycharmProjects/Statistical%20Arbitrage/Copulas%20pair%20trading/hidden_markov.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     start_date\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2022-03-01\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasperchong/PycharmProjects/Statistical%20Arbitrage/Copulas%20pair%20trading/hidden_markov.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     end_date\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m2023-03-01\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasperchong/PycharmProjects/Statistical%20Arbitrage/Copulas%20pair%20trading/hidden_markov.ipynb#X46sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\u001b[39m.\u001b[39mto_dataframe()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasperchong/PycharmProjects/Statistical%20Arbitrage/Copulas%20pair%20trading/hidden_markov.ipynb#X46sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m price_start \u001b[39m=\u001b[39m stocks_dataframe[\u001b[39m\"\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasperchong/PycharmProjects/Statistical%20Arbitrage/Copulas%20pair%20trading/hidden_markov.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m price_end \u001b[39m=\u001b[39m stocks_dataframe[\u001b[39m\"\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openbb' has no attribute 'stocks'"
     ]
    }
   ],
   "source": [
    "# Get the nominal price returns for 2022\n",
    "stocks_dataframe = obb.stocks.load(\n",
    "    \"BMWYY\",\n",
    "    start_date=\"2022-03-01\",\n",
    "    end_date=\"2023-03-01\"\n",
    ").to_dataframe()\n",
    "price_start = stocks_dataframe[\"close\"].iloc[0]\n",
    "price_end = stocks_dataframe[\"close\"].iloc[-1]\n",
    "\n",
    "nominal_returns = (price_end - price_start) / price_start\n",
    "print(f\"Nominal price returns: {nominal_returns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ROUTER_stocks.load of /stocks\n",
       "    /ca\n",
       "    /fa\n",
       "    load\n",
       "    multiples\n",
       "    news\n",
       "    /options\n",
       "    quote\n",
       "    >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
